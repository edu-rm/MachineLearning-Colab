{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHsz9X3p66Ld6Wvh0DysNB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqvFJfKiaJnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miOA1pBKavdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "# Importing the libraries\n",
        "# Library is a tool that you can do a specific job\n",
        "# Inputs -> Library -> Outputs\n",
        "\n",
        "# 3 Essentials libraries, every time.\n",
        "\n",
        "# Numpy: contém ferramentas matemáticas.\n",
        "import numpy as np \n",
        "\n",
        "# To plot nice charts\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# To import datasets and manage datasets\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Datasets/Data.csv')\n",
        "# Vamos dividir as variaveis dependentes das independentes\n",
        "\n",
        "# [: = All the lines. :-1] = All the columns except the last one \n",
        "X = dataset.iloc[:,:-1].values\n",
        "\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n",
        "# y = dataset.iloc[:,3].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAmARGVobKHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing the data \n",
        "# We can remove that lines, but it can be dangerous becuse these lines can have crucial information\n",
        "\n",
        "# To take the mean of columns.\n",
        "\n",
        "# SK Learn - Imputer : lead with the missing data\n",
        "# Imputer = class\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY0Em14-bShB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding categorical data\n",
        "\n",
        "# Machine learning é completamente matemática, então como ficará os atrbutos de texto ? \n",
        "# need to encode, text into numbers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Dummy Encoding\n",
        "\n",
        "# Invés de usar uma coluna, usaremos 3 colunas(Espanha, França e Alemanha) \n",
        "# com valores binários\n",
        "\n",
        "# Número de colunas que vão ser criadas = Número de categorias\n",
        "\n",
        "labelencoder_X = LabelEncoder() \n",
        "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
        "\n",
        "ct = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],   \n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "# Precisamos fazer o mesmo com a variavel dependente,\n",
        "# o modelo sabe que ela é categórica então basta usar \n",
        "# o LabelEncoder: precisamos criar um outro objeto pois\n",
        "# labelencoder_X ja foi preenchido(fit) com X\n",
        "\n",
        "labelencoder_y = LabelEncoder() \n",
        "y = labelencoder_y.fit_transform(y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wymVlpswsPgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "# Machine learning se trata se uma máquina que vai aprender alguma coisa\n",
        "# o algritmo aprende através dos dados pra fazer previsões\n",
        "\n",
        "# Vamos criar o modelo e treiná-lo com um conjunto de dados, \n",
        "# então precisamos testar em um novo set (que é diferente do primeiro).\n",
        "\n",
        "# O modelo estabelecerá corelações entre as váriaveis independentes e dependentes\n",
        "# E uma vez que ela entender a corelação nós testaremos com o set de treino\n",
        "\n",
        "# Quanto \"melhor\" ele entender as corelações no set de treino maior  \n",
        "# a taxa de acerto no set de teste\n",
        "\n",
        "# Mas se ele aprender muito \"de cor\" as relações no set de treino, \n",
        "# ou seja, não enteder, ele terá dificuldades para prever o set de \n",
        "# teste. Aperendendo de cor as relações ele não entenderá muito bem\n",
        "# a lógica. \n",
        "# Isso se chama Overfitting (regularisations techniques)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAIdfGQFCRc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "# A coluna age (27 - 50) e salary (48 k - 90 k ) estão em escalas diferentes,\n",
        "# E isso causará problemas no nosso modelo\n",
        "\n",
        "# Existem vários de modelos de ML que são baseados na distância de Euclidean\n",
        "# E = sqrt((x2 - x1)^2 + (y2 - y1)^2)\n",
        "# Como o salário tem valor muito superior dos de idade, a distância euclidiana \n",
        "# será dominada pela coluna salário \n",
        "\n",
        "# Por isso precisamos colocar as todas as váriaveis na mesma escala \n",
        "# -1 a 1\n",
        "\n",
        "# Há muitas formas de colocar na mesma escala\n",
        "# Basicamente as equações abaixo farão que nenhuma variável domine a outra\n",
        "\n",
        "# Standardisation\n",
        "# x = ( x - mean(x) )/( SD( x ) )\n",
        "\n",
        "# Normalization\n",
        "# x = ( x - min(x) )/( max(x) - min(x) )\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "# Mesmo se usarmos modelos que não utilizam distância Euclidiana precisaremos \n",
        "# colocar os dados na mesma escala, pois se não demorará,em alguns casos\n",
        "# muito tempo para executar.\n",
        "\n",
        "# Uma vez criado um objeto StandScaler e preenchido com o X_teste primeiro \n",
        "# precisaremos usar o mesmo para o X_train dessa forma os dois estarão com \n",
        "# escalas de mesma base\n",
        "\n",
        "# Não precisamos fazer com y neste caso, só precisaremos aplicar no y quando a \n",
        "# variável dependente possuir um grande intervalo nos seus valores, em outras\n",
        "# palavras: neste caso a variável dependente é apenas composta por valores \n",
        "# categóricos. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTyZECbeOF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65a6b3ba-1c29-45c9-f263-7d19d52b5bb8"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        ,  2.64575131, -0.77459667, -1.45882927, -0.90166297],\n",
              "       [-1.        ,  2.64575131, -0.77459667,  1.98496442,  2.13981082]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}