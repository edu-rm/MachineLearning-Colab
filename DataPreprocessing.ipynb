{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYMQFdV+s+qWG9lI0SDkdX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqvFJfKiaJnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miOA1pBKavdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "# Importing the libraries\n",
        "# Library is a tool that you can do a specific job\n",
        "# Inputs -> Library -> Outputs\n",
        "\n",
        "# 3 Essentials libraries, every time.\n",
        "\n",
        "# Numpy: contém ferramentas matemáticas.\n",
        "import numpy as np \n",
        "\n",
        "# To plot nice charts\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# To import datasets and manage datasets\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Datasets/Data.csv')\n",
        "# Vamos dividir as variaveis dependentes das independentes\n",
        "\n",
        "# [: = All the lines. :-1] = All the columns except the last one \n",
        "X = dataset.iloc[:,:-1].values\n",
        "\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n",
        "# y = dataset.iloc[:,3].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAmARGVobKHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing the data \n",
        "# We can remove that lines, but it can be dangerous becuse these lines can have crucial information\n",
        "\n",
        "# To take the mean of columns.\n",
        "\n",
        "# SK Learn - Imputer : lead with the missing data\n",
        "# Imputer = class\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY0Em14-bShB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding categorical data\n",
        "\n",
        "# Machine learning é completamente matemática, então como ficará os atrbutos de texto ? \n",
        "# need to encode, text into numbers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Dummy Encoding\n",
        "\n",
        "# Invés de usar uma coluna, usaremos 3 colunas(Espanha, França e Alemanha) \n",
        "# com valores binários\n",
        "\n",
        "# Número de colunas que vão ser criadas = Número de categorias\n",
        "\n",
        "labelencoder_X = LabelEncoder() \n",
        "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
        "\n",
        "ct = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],   \n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "# Precisamos fazer o mesmo com a variavel dependente,\n",
        "# o modelo sabe que ela é categórica então basta usar \n",
        "# o LabelEncoder: precisamos criar um outro objeto pois\n",
        "# labelencoder_X ja foi preenchido(fit) com X\n",
        "\n",
        "labelencoder_y = LabelEncoder() \n",
        "y = labelencoder_y.fit_transform(y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wymVlpswsPgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "# Machine learning se trata se uma máquina que vai aprender alguma coisa\n",
        "# o algritmo aprende através dos dados pra fazer previsões\n",
        "\n",
        "# Vamos criar o modelo e treiná-lo com um conjunto de dados, \n",
        "# então precisamos testar em um novo set (que é diferente do primeiro).\n",
        "\n",
        "# O modelo estabelecerá corelações entre as váriaveis independentes e dependentes\n",
        "# E uma vez que ela entender a corelação nós testaremos com o set de treino\n",
        "\n",
        "# Quanto \"melhor\" ele entender as corelações no set de treino maior  \n",
        "# a taxa de acerto no set de teste\n",
        "\n",
        "# Mas se você aprender muito \"de cor\" as relações no set de treino, \n",
        "# ou seja, não enteder, ele terá dificuldades para prever o set de \n",
        "# treino. Aperendendo de cor as relações ele não entenderá muito bem\n",
        "# a lógica. \n",
        "# Isso se chama Overfitting (regularisations techniques)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OjOPTYH7HFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "391a9a9b-e9a8-4c77-ea86-cefe46953ed0"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}